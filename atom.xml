<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>LATTE world</title>
  <subtitle>Semiconductor and Data.</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://kzhoulatte.github.io/"/>
  <updated>2018-01-15T10:44:44.000Z</updated>
  <id>https://kzhoulatte.github.io/</id>
  
  <author>
    <name>Kuan Zhou</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>instacart</title>
    <link href="https://kzhoulatte.github.io/2018/01/14/instacart/"/>
    <id>https://kzhoulatte.github.io/2018/01/14/instacart/</id>
    <published>2018-01-15T00:03:36.000Z</published>
    <updated>2018-01-15T10:44:44.000Z</updated>
    
    <content type="html"><![CDATA[<p>Instacart算是我第一个kaggle比赛，幸运拿到了85th of 2623的名次，其实这个比赛的内容还是很丰富的，比如类似数据库结构的datasets、包含简单的word2vec、feature engineering、F1 maximization、CV、PCA、调参以及ensemble。</p>
<p>虽然没有很fancy的模型和技巧，但是feature engineering和对数据的理解还是挺重要的。<br>整理的pdf presentation file：</p>
<p><a href="https://drive.google.com/open?id=13KDcnEjAuhHGU22bs1ipVQtJihS2Lw-Q" target="_blank" rel="external">https://drive.google.com/open?id=13KDcnEjAuhHGU22bs1ipVQtJihS2Lw-Q</a></p>


	<div class="row">
    <embed src="./myinstacart.pdf" width="100%" height="550" type="application/pdf">
	</div>



]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Instacart算是我第一个kaggle比赛，幸运拿到了85th of 2623的名次，其实这个比赛的内容还是很丰富的，比如类似数据库结构的datasets、包含简单的word2vec、feature engineering、F1 maximization、CV、PCA、
    
    </summary>
    
    
      <category term="kaggle" scheme="https://kzhoulatte.github.io/tags/kaggle/"/>
    
  </entry>
  
  <entry>
    <title>santamatch</title>
    <link href="https://kzhoulatte.github.io/2018/01/14/santamatch/"/>
    <id>https://kzhoulatte.github.io/2018/01/14/santamatch/</id>
    <published>2018-01-14T23:47:09.000Z</published>
    <updated>2018-01-15T08:00:09.000Z</updated>
    
    <content type="html"><![CDATA[<p>关于projects, 虽然在santa match challenge里成功使用了ortools里的min cost max flow method，对于问题的formation是基本了解的，但是对于这个图论算法本身不了解，比如为什么这个图论算法可以这么快解决本是NP hard的integer programming问题。</p>
<p>稍微了解之后，发现mincostmaxflow在Computer vision还有很多应用。<br>而对于这个图论问题的解法本身，这里简单记录：</p>
<p>Min Cost Max Flow的问题主要解决思路是：最大流的条件是当且仅当residual network不存在Augmenting Path。而Augmenting path定义：假如有这么一条路，这条路从源点开始一直一段一段的连到了汇点，并且，这条路上的每一段都满足流量 &lt; 容量。那么，我们一定能找到这条路上的每一段的(容量-流量)的值当中的最小值delta。我们把这条路上每一段的流量都加上这个delta，一定可以保证这个流依然是可行流。这样我们就得到了一个更大的流，他的流量是之前的流量+delta，而这条路就叫做增广路径。</p>
<p>再看之后的，不得不说不是时候，暂且放下其余的细节。 </p>
<p>贴个索引：<a href="http://mindlee.com/2011/11/19/network-flow/" target="_blank" rel="external">http://mindlee.com/2011/11/19/network-flow/</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于projects, 虽然在santa match challenge里成功使用了ortools里的min cost max flow method，对于问题的formation是基本了解的，但是对于这个图论算法本身不了解，比如为什么这个图论算法可以这么快解决本是NP h
    
    </summary>
    
    
      <category term="kaggle" scheme="https://kzhoulatte.github.io/tags/kaggle/"/>
    
  </entry>
  
  <entry>
    <title>apply</title>
    <link href="https://kzhoulatte.github.io/2018/01/14/apply/"/>
    <id>https://kzhoulatte.github.io/2018/01/14/apply/</id>
    <published>2018-01-14T19:02:54.000Z</published>
    <updated>2018-01-15T03:38:44.000Z</updated>
    
    <content type="html"><![CDATA[<p>六点多听Data App Lab的讲座，Jason老师提到明天是节假日，我才想起来明天休息啊，这也是小惊喜吧。整理了一下我之前的文件夹等之后，加上下午以及周五晚上和师兄聊了好久之后，觉得可以稍微写点现在的想法。</p>
<p>首先kaggle算是有了不错的成绩，接近全服top 1%了，剩下的gold medal以及master只能说走着瞧了，剩下的精力应该主要都放在面试准备上了。</p>
<p>同样的data scientist其实不同的工作内容性质也相差很大，待遇也是。硅谷偏R&amp;D以及algorithms的需要比较强的CS和数理基础，level4大概能到25~30的package，而一般的analytics相关的，比较偏向于数据分析处理，哪怕flag公司，比较好的也是15~20，而一般的平均水平大概在10~15。所以其实选择的余地和弹性还是很大。</p>
<p>kaggle目前来说，虽然评价不一，但无疑是转专业的利器，但是部分小公司还是很认可的。</p>
<p>这里先以R&amp;D的要求看自己吧，kaggle虽然做了不少，但是动手能力还是不算强，统计和算法能力不够。</p>
<p>现在的想法是：kaggle暂时放下了，更多时间把简历相关的细节搞清楚(know your resume)，把kaggle相关的经验消化清楚，推一推公式，把自己的理解整理出来，包括通过github把流程规范化，同时提高from scratch的能力或者说不google的情况下的能力。提高统计／分析／算法／优化相关的背景，把自己的理解表达规范化，英语交流能力也可以提高一下。</p>
<p>当然以后把这些理解写在这里。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;六点多听Data App Lab的讲座，Jason老师提到明天是节假日，我才想起来明天休息啊，这也是小惊喜吧。整理了一下我之前的文件夹等之后，加上下午以及周五晚上和师兄聊了好久之后，觉得可以稍微写点现在的想法。&lt;/p&gt;
&lt;p&gt;首先kaggle算是有了不错的成绩，接近全服to
    
    </summary>
    
    
      <category term="jobhunting" scheme="https://kzhoulatte.github.io/tags/jobhunting/"/>
    
  </entry>
  
  <entry>
    <title>competition</title>
    <link href="https://kzhoulatte.github.io/2017/12/08/competition/"/>
    <id>https://kzhoulatte.github.io/2017/12/08/competition/</id>
    <published>2017-12-09T02:53:40.000Z</published>
    <updated>2017-12-09T11:07:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>今天学习了一下kaggle competition的challenge和coursera的how to win kaggle，其实收获还是很多的，但是细节还得慢慢消化。这里在睡前稍微整理一下：</p>
<p>重点：1）Ploting for EDA; 2) Statistical inference: t-test,chi squared test, etc; 3)Model分类和划分特点；4）根据不同model的feature scaling，feature transformation，outlier，fillna等；5）一些特别的feature的产生和处理方式，比如images／texts；6）Data leaks也是重要的；7）Bag of words和word2vec相关；8）不同metrics的分析以及特点，利用；9）利用PCA等产生特别的feature；等等。</p>
<p>重点的重点还是通过EDA对数据的特点有很好的认识，并和model和metrics结合起来。</p>
<p>包括AUC等。</p>
<p>No free lunch theorm，所以多思考多尝试吧。</p>
<p>ps：稍微有点了NLP的兴趣，但是还是先刷题吧，就酱。 </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天学习了一下kaggle competition的challenge和coursera的how to win kaggle，其实收获还是很多的，但是细节还得慢慢消化。这里在睡前稍微整理一下：&lt;/p&gt;
&lt;p&gt;重点：1）Ploting for EDA; 2) Statisti
    
    </summary>
    
    
      <category term="kaggle" scheme="https://kzhoulatte.github.io/tags/kaggle/"/>
    
  </entry>
  
  <entry>
    <title>Black-Scholes</title>
    <link href="https://kzhoulatte.github.io/2017/12/02/Black-Scholes/"/>
    <id>https://kzhoulatte.github.io/2017/12/02/Black-Scholes/</id>
    <published>2017-12-02T14:42:18.000Z</published>
    <updated>2017-12-03T00:10:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>今天早上听了一节关于Quant Interview的公开课，对比之前相同老师不同内容的另外一次，觉得确实还是明白了很多，对这个领域自我觉得算是入门了，理解还不够。</p>
<p>然后看了两章的Pricing the future, 眼前有十七八世纪那种简易交易所外面熙熙攘攘的感觉，同时确实觉得在这样的环境下，法国人雷格纳特在交易所做事，能够慢慢领悟出一本书的规律-《概率计算和股票交易哲学》同时还归纳出数学表示，甚至用虚数试图的解释。这应该就是所谓的talent吧。</p>
<p>同时下午打算好好研究一下量化定价的核心（圣杯）-BS公式。stochastic calculus/arbitrage/risk neutral这些都是关键的，暂放了。</p>
<p>根据之前看edx课程以及下午的研究，先暂时写下自己对于fixed income金融衍生品的理解：</p>
<p>金融衍生品的出现其实挺正常的，因为人们想要规避风险，但是后来就需要考虑规避风险是要付出代价的，所以需要考虑多少代价合适。所以最早也是最基本的思路，在没有任何模型的基础上，是可以通过replicating portfolio计算的，把一个portfolio的payoff当作期权的价格。这里用到的基本想法是市场上有那么多talent那么多眼睛，市场不应该存在arbitrage的机会，即无风险套利。</p>
<p>但是这些只适用于简单的options，对于复杂的计算，还是需要一些模型处理。</p>
<p>这时最先开始的应该是风险中立定价方法和鞅定价方法。这两种是从模型上给定了假设基础。比如风险中立定价虽然，严格来说不是假设，但是却提供了一个最简单明白的测度空间。他把期权的价格和投资者的风险偏好直接去除了，告诉我们衡量期权价格时，应该只关注于期权本身的期望以及其无风险折现的过程。但其实模型对于非风险中立测度空间也是成立的。这些可以参考：<a href="https://www.zhihu.com/question/26724322。" target="_blank" rel="external">https://www.zhihu.com/question/26724322。</a></p>
<p>接着另外的是鞅定价模型，鞅首先就是假设赌博或者说足够随机的股票过程中，这一次的期望是和上一次的赌博无关的。所以有时候，求价格时，可以计算股价随机过程，使得在风险中立测度下更简单计算。</p>
<p>从而来到了股票价格的随机过程描述。首先这里再想到雷格纳特自己观察到了股价变化和时间根的关系，也该算是这一切的开始吧。股价最重要的一个假设应该是对数正态分布，而这又是时间序列的一个共有的特性，都可以从复利的角度理解吧。</p>
<p>然后通过这些和布朗运动的联系，又有了主要的两个定价方法，二项定价模型和BSM模型：</p>
<p>二项定价模型，其实比较简单，但是又是非常强大。他只把股票每个时间点的变化想象的只有两种方式，但是如果时间足够密，又能够包含了庞大的可能性；</p>
<p>BSM模型，七大假设就先不罗列了。推导思路就是根据对数正态分布的性质，分别推导期权是否被执行的P和执行所得E的表示，最后把正太分布的性质等都参杂在一起，也就变成了包含d1，d2的一个看起来很吓人的公式。</p>
<p>这样到此为止，最大的问题就是布朗运动，维纳过程是如何很好的解释清楚这些模型的基础的。</p>
<p>维纳工程和布朗运动类似，而在伊藤引理的框架下，股价或者其他金融产品是服从，一个固定利率加上一个随机过程的微风方程的，而在这个方程和stochastic calculus的框架下，其实就可以推导出BS formula等结论。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天早上听了一节关于Quant Interview的公开课，对比之前相同老师不同内容的另外一次，觉得确实还是明白了很多，对这个领域自我觉得算是入门了，理解还不够。&lt;/p&gt;
&lt;p&gt;然后看了两章的Pricing the future, 眼前有十七八世纪那种简易交易所外面熙熙攘攘
    
    </summary>
    
    
      <category term="quant" scheme="https://kzhoulatte.github.io/tags/quant/"/>
    
  </entry>
  
  <entry>
    <title>最近所看-犹太恩怨</title>
    <link href="https://kzhoulatte.github.io/2017/12/01/%E6%9C%80%E8%BF%91%E6%89%80%E7%9C%8B/"/>
    <id>https://kzhoulatte.github.io/2017/12/01/最近所看/</id>
    <published>2017-12-01T13:23:01.000Z</published>
    <updated>2017-12-01T21:46:33.000Z</updated>
    
    <content type="html"><![CDATA[<p>在看Pricing the future的时候，讲到了首位书面阐述期权的人-约瑟夫.德拉维加，是1650年出生于马拉诺家庭的一位犹太人，而这个名词马拉诺家庭则是指被西班牙宗教裁判力量而强制改信基督教的犹太人。这里先不说德拉维加的书是多大影响，恩恩怨怨搞出这么多的专有名词。我最好奇的是，犹太人和基督教到底是因为什么结怨，成了这么多事情的导火索。</p>
<p>学习了以后，发现主要原因是耶稣的身份问题，其他还有很多：<br>1）犹太教是西亚的希伯来人发展起来的宗教，其实基督教是在犹太教的基础上发展起来的；<br>2）犹太教的主要教义是圣经.旧约，而不太承认新约;<br>3）除了一些其他教义外，犹太教尤其不承认耶稣就是预言中的神的儿子也就是所谓的弥赛亚，而相信真正的弥赛亚还没来到；<br>4）犹太教不相信耶稣的原因有很多，包括很多没有实现的预言，基督教说你们也太没耐心了，耶稣会”再次降临的，等他再荣耀归来，会审判一切死人活人，信从他的将得永生”；但其实可能最主要的原因就是耶稣既不是犹太人也不帮犹太人说话，不带领犹太人回以色列；<br>5）耶稣的死刑是被犹太祭司所害；<br>6）美国还是很支持以色列以及耶路撒冷的；</p>
<p>关于锡安主义，我也精神上支持，不知道我属不属于锡安主义了。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在看Pricing the future的时候，讲到了首位书面阐述期权的人-约瑟夫.德拉维加，是1650年出生于马拉诺家庭的一位犹太人，而这个名词马拉诺家庭则是指被西班牙宗教裁判力量而强制改信基督教的犹太人。这里先不说德拉维加的书是多大影响，恩恩怨怨搞出这么多的专有名词。我
    
    </summary>
    
    
      <category term="reading" scheme="https://kzhoulatte.github.io/tags/reading/"/>
    
  </entry>
  
  <entry>
    <title>leetcode</title>
    <link href="https://kzhoulatte.github.io/2017/10/02/leetcode/"/>
    <id>https://kzhoulatte.github.io/2017/10/02/leetcode/</id>
    <published>2017-10-02T16:27:23.000Z</published>
    <updated>2017-10-02T23:32:23.000Z</updated>
    
    <content type="html"><![CDATA[<p>Leetcode 博客</p>
<p>“刷题是开心的，游戏是苦逼的”<br>刷题博客，记录刷题过程，总结算法，效率优先。<br>同时进行Big Data的Projects训练。</p>
<p>Edx pricing options，系统设计, Research, Kaggle等。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Leetcode 博客&lt;/p&gt;
&lt;p&gt;“刷题是开心的，游戏是苦逼的”&lt;br&gt;刷题博客，记录刷题过程，总结算法，效率优先。&lt;br&gt;同时进行Big Data的Projects训练。&lt;/p&gt;
&lt;p&gt;Edx pricing options，系统设计, Research, Kaggl
    
    </summary>
    
    
      <category term="leetcode" scheme="https://kzhoulatte.github.io/tags/leetcode/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop and Spark</title>
    <link href="https://kzhoulatte.github.io/2017/06/01/HadoopSpark/"/>
    <id>https://kzhoulatte.github.io/2017/06/01/HadoopSpark/</id>
    <published>2017-06-01T18:07:57.000Z</published>
    <updated>2017-06-02T04:24:05.000Z</updated>
    
    <content type="html"><![CDATA[<p>机器学习方向其实确实太热了，Hadoop和Spark的需求可能比机器学习方向更合适。</p>
<p>之后学习补充一下Hadoop和Spark的入门。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;机器学习方向其实确实太热了，Hadoop和Spark的需求可能比机器学习方向更合适。&lt;/p&gt;
&lt;p&gt;之后学习补充一下Hadoop和Spark的入门。&lt;/p&gt;

    
    </summary>
    
    
      <category term="bigdata" scheme="https://kzhoulatte.github.io/tags/bigdata/"/>
    
  </entry>
  
  <entry>
    <title>Job hunting</title>
    <link href="https://kzhoulatte.github.io/2017/05/31/Jobhunting/"/>
    <id>https://kzhoulatte.github.io/2017/05/31/Jobhunting/</id>
    <published>2017-05-31T13:49:16.000Z</published>
    <updated>2017-05-31T20:52:09.000Z</updated>
    
    <content type="html"><![CDATA[<p>和刚找到Facebook Data Engineer工作的师兄聊天，其实发现最后可能是因为Hadoop等背景，Kaggle如果已经有不错的成绩，Hadoop这些才是加分项。</p>
<p>先Mark一下。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;和刚找到Facebook Data Engineer工作的师兄聊天，其实发现最后可能是因为Hadoop等背景，Kaggle如果已经有不错的成绩，Hadoop这些才是加分项。&lt;/p&gt;
&lt;p&gt;先Mark一下。&lt;/p&gt;

    
    </summary>
    
    
      <category term="jobhunting" scheme="https://kzhoulatte.github.io/tags/jobhunting/"/>
    
  </entry>
  
  <entry>
    <title>GeoGuessr</title>
    <link href="https://kzhoulatte.github.io/2017/05/28/GeoGuessr/"/>
    <id>https://kzhoulatte.github.io/2017/05/28/GeoGuessr/</id>
    <published>2017-05-28T13:40:10.000Z</published>
    <updated>2017-05-28T20:41:20.000Z</updated>
    
    <content type="html"><![CDATA[<p>试玩了一下GeoGuessr.</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;试玩了一下GeoGuessr.&lt;/p&gt;

    
    </summary>
    
    
      <category term="fun" scheme="https://kzhoulatte.github.io/tags/fun/"/>
    
  </entry>
  
  <entry>
    <title>GPU Architecture</title>
    <link href="https://kzhoulatte.github.io/2017/05/10/GPUArchitecture/"/>
    <id>https://kzhoulatte.github.io/2017/05/10/GPUArchitecture/</id>
    <published>2017-05-10T18:23:02.000Z</published>
    <updated>2017-05-12T00:14:05.000Z</updated>
    
    <content type="html"><![CDATA[<p>最近NVIDIA的股票又在疯涨。<b><br>AMD的Vega在GDC大会上公布，NVIDIA的Volta架构GV100也在GTC2017上曝光。</b></p>
<p>继Tesla/Fermi/Kepler/Maxwell/Pascal之后，Volta的新架构备受瞩目。<b><br>挖坑学习一下GPU架构及原理。</b></p>
<p>参考：<a href="https://chenrudan.github.io/blog/2015/12/20/introductionofgpuhardware.html" target="_blank" rel="external">https://chenrudan.github.io/blog/2015/12/20/introductionofgpuhardware.html</a></p>
<p>里面已经写得非常清楚详细，主要的总结是：</p>
<p>（1）显卡结构本质上没什么区别，注意核心参数：处理器核心，工作频率，显存位宽，单卡or双卡。对于深度学习，因为数据量大，核心数和显存大小比较重要。同时需要注意CUDA需要让所有的core都工作。</p>
<p>（2）显卡的SM流处理器簇是GPU的核心部分，其中包括了各种调度器共享内存等等。同时不同架构的区别往往在于SM的设计，比如shared memory大小，比如FP unit，INT unit，DP unit的相互比例关系。这些关系都可以决定这块显卡的性能以及适合做什么工作。（ps：深度学习使用的M系列显卡是单精度的，深度学习并不要求双精度）</p>
<p>（3）TESLA的K型号卡适合高性能科学计算，同时支持双精度，但是不怎么适合深度学习。</p>
<p>（4）针对不同的应用，开源库都已经挺完整。卷积计算：cudnn；卷积神经网络：caffe，torch；rnn：mxnet，tensorflow等。</p>
<p>（5）相互的架构连接以及内存技术也一直在更新，比如ECC内存，HBM内存。</p>
<p>（6）如果使用多张显卡，注意电源的选择。</p>
<p>关于AMD和NVIDIA的显卡区别，目前看主要的有：</p>
<p>（1）两者面向更高计算性能的途径不一样，NVIDIA倾向于more capable stream processors allowing for slightly more complex calculations; 而AMD倾向smaller, less complex stream processors。所以两者在不同类型的计算任务上性能各有优劣。</p>
<p>（2）在图像显示游戏性能方面，虽然也各有优劣。但是由于目前只有CUDA完美支持Physx物理加速（Physx可以在GPU或加速卡），所以N卡比较占优。</p>
<p>而新的GV100芯片，除了先进的L1 Cache和Memory等技术加线程调度技术，主要新特性是加入了Tensor Core，所以非常适合深度学习。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近NVIDIA的股票又在疯涨。&lt;b&gt;&lt;br&gt;AMD的Vega在GDC大会上公布，NVIDIA的Volta架构GV100也在GTC2017上曝光。&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;继Tesla/Fermi/Kepler/Maxwell/Pascal之后，Volta的新架构备受瞩目。&lt;
    
    </summary>
    
    
      <category term="GPU" scheme="https://kzhoulatte.github.io/tags/GPU/"/>
    
  </entry>
  
  <entry>
    <title>Keras含义</title>
    <link href="https://kzhoulatte.github.io/2017/05/03/Keras/"/>
    <id>https://kzhoulatte.github.io/2017/05/03/Keras/</id>
    <published>2017-05-03T16:34:07.000Z</published>
    <updated>2017-05-03T23:46:17.000Z</updated>
    
    <content type="html"><![CDATA[<p>虽然Keras已经不被很多人推荐，但是觉得它的含义挺有趣。</p>
<p>Keras 是基于Theano的一个深度学习框架，它的设计参考了Torch，用Python编写，是一个高度模块化的神经网络库，支持GPU和CPU。</p>
<p>Keras 是古希腊语中”角”的意思, 最早出现在古希腊的《奥德赛》. 梦神被分为两派. 一派用虚假景象欺骗人们,他们通过象牙之门来到地面. 一派启示即将经历的未来, 他们通过角之门来到地面. 所以Keras代表“真实/实现”的一方，与“虚幻/欺骗”相对。就如它的名字，Keras 吹响向“深度学习”前进的号角，扫除“深度学习”高不可攀的虚相。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;虽然Keras已经不被很多人推荐，但是觉得它的含义挺有趣。&lt;/p&gt;
&lt;p&gt;Keras 是基于Theano的一个深度学习框架，它的设计参考了Torch，用Python编写，是一个高度模块化的神经网络库，支持GPU和CPU。&lt;/p&gt;
&lt;p&gt;Keras 是古希腊语中”角”的意思,
    
    </summary>
    
    
      <category term="deep learning" scheme="https://kzhoulatte.github.io/tags/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title>RPA understanding</title>
    <link href="https://kzhoulatte.github.io/2017/04/20/RPA-understanding/"/>
    <id>https://kzhoulatte.github.io/2017/04/20/RPA-understanding/</id>
    <published>2017-04-20T16:34:02.000Z</published>
    <updated>2017-04-25T06:22:14.000Z</updated>
    
    <content type="html"><![CDATA[<p>RPA here is Random Phase Approximation, which is one of the basis approximation in DFT calculation and condensed matter physics. This is a note which I gradually got better understanding of it. <b></b></p>
<p>In the RPA, electrons are assumed to respond only to the total electric potential V(r) which is the sum of the external perturbing potential Vext(r) and a screening potential Vsc(r). The external perturbing potential is assumed to oscillate at a single frequency ω, so that the model yields via a self-consistent field (SCF) method a dynamic dielectric function denoted by εRPA(k, ω).<b></b></p>
<p>The contribution to the dielectric function from the total electric potential is assumed to average out, so that only the potential at wave vector k contributes. This is what is meant by the random phase approximation. <b></b></p>
<p>In DFT, the treatment of exchange and correlation in terms of ‘‘exact-exchange plus correlation in the random-phase approximation’’ offers a promising avenue in accurate simulations.</p>
<p>From wiki.com and article:”Random-phase approximation and its applications in computational chemistry and materials science”, DOI 10.1007/s10853-012-6570-4.  </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;RPA here is Random Phase Approximation, which is one of the basis approximation in DFT calculation and condensed matter physics. This is 
    
    </summary>
    
    
      <category term="notes" scheme="https://kzhoulatte.github.io/tags/notes/"/>
    
  </entry>
  
  <entry>
    <title>2D materials-My understanding</title>
    <link href="https://kzhoulatte.github.io/2017/04/17/2Dmaterials/"/>
    <id>https://kzhoulatte.github.io/2017/04/17/2Dmaterials/</id>
    <published>2017-04-17T14:00:19.000Z</published>
    <updated>2017-04-19T01:36:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>我的PhD研究领域是2D materials的光学和电学性质，尤其是电子输运性质。<b><br>一些”科普向”的理解：<b></b></b></p>
<p>摘自<a href="https://www.scientificamerican.com/article/graphene-finally-gets-an-electronic-on-off-switch/" target="_blank" rel="external">https://www.scientificamerican.com/article/graphene-finally-gets-an-electronic-on-off-switch/</a>:<b><br>“Semiconductors are defined by their band gap: the energy required to excite an electron stuck in the valence band, where it cannot conduct electricity, to the conduction band, where it can. The band gap needs to be large enough so that there is a clear contrast between a transistor’s on and off states, and so that it can process information without generating errors.” <b></b></b></p>
<p>Relaxation time and charge density as a function of energy level calculation for graphene: (literature reading…)</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我的PhD研究领域是2D materials的光学和电学性质，尤其是电子输运性质。&lt;b&gt;&lt;br&gt;一些”科普向”的理解：&lt;b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;摘自&lt;a href=&quot;https://www.scientificamerican.com/article/graph
    
    </summary>
    
    
      <category term="2Dmaterials" scheme="https://kzhoulatte.github.io/tags/2Dmaterials/"/>
    
  </entry>
  
  <entry>
    <title>coding</title>
    <link href="https://kzhoulatte.github.io/2017/04/12/coding/"/>
    <id>https://kzhoulatte.github.io/2017/04/12/coding/</id>
    <published>2017-04-13T02:28:50.000Z</published>
    <updated>2017-04-13T09:59:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp; &ensp; 好好研究了一下Matlab的3D画图功能，参考书籍是《精通Matlab》张志涌。才发现在plot3，meshgrid和surf三个基本命令之后，Matlab的潜能才刚刚是个开始。<b><br>&ensp; &ensp; colormap加上shading，view，light，material，alpha几个参数命令，由colormap自然可以得到很多绚丽配色的图，惊喜是light和material的调整就好像摄影里的灯光和美工一样，能够立马让图像获得质感，可以制作符合出版要求的图像。<b><br>&ensp; &ensp; 同时，一个小发现是，github以及matlab自己的file exchange上，有很多人开发了各种matlab schemer，可以修改matlab的界面。尝试了之后觉得还不错，比较喜欢sublime的仿制版本。<b><br>&ensp; &ensp; 说到sublime这个被称作性感编辑器的家伙, 下载了之后打开确实小有惊艳，非常有质感的编辑器，加上那么高的灵活性和传说中的各种神插件。我就把它先默默放在那里吧，以后需要的时候，再好好研究一下。<b></b></b></b></b></p>
<p>&ensp; &ensp; Coding… </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;ensp; &amp;ensp; 好好研究了一下Matlab的3D画图功能，参考书籍是《精通Matlab》张志涌。才发现在plot3，meshgrid和surf三个基本命令之后，Matlab的潜能才刚刚是个开始。&lt;b&gt;&lt;br&gt;&amp;ensp; &amp;ensp; colormap加上sha
    
    </summary>
    
    
      <category term="coding" scheme="https://kzhoulatte.github.io/tags/coding/"/>
    
  </entry>
  
  <entry>
    <title>编辑室的故事</title>
    <link href="https://kzhoulatte.github.io/2017/04/09/%E7%BC%96%E8%BE%91%E5%AE%A4%E7%9A%84%E6%95%85%E4%BA%8B/"/>
    <id>https://kzhoulatte.github.io/2017/04/09/编辑室的故事/</id>
    <published>2017-04-10T00:52:21.000Z</published>
    <updated>2017-04-12T09:25:19.000Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp; 最近看完了《编辑室的故事》，除了被片尾曲些许着迷，更多的感叹是：</p>
<p>&ensp; “这人呐，贵在清醒”<br>&ensp; “打在胎里，随时可能流产；当妈的一口烟就可能长成畸形，长慢了心脏缺损，长快了就6指；扛过十个月，一不留神让产钳把脑袋夹扁了，都躲过去了。小儿麻痹，百日咳，猩红热，大脑炎，前面等着；哭起来呛奶，走起来摔跤，摸水水烫，碰火火燎；是个东西撞上就是半死，钙多了不长个，钙少了罗圈腿；混到能吃饭能出门，天上下雹子，地下跑汽车，大街小巷是个暗处就躲着坏人，赶上谁都是个九死一生。”</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;ensp; 最近看完了《编辑室的故事》，除了被片尾曲些许着迷，更多的感叹是：&lt;/p&gt;
&lt;p&gt;&amp;ensp; “这人呐，贵在清醒”&lt;br&gt;&amp;ensp; “打在胎里，随时可能流产；当妈的一口烟就可能长成畸形，长慢了心脏缺损，长快了就6指；扛过十个月，一不留神让产钳把脑袋夹扁了，
    
    </summary>
    
    
      <category term="观后感" scheme="https://kzhoulatte.github.io/tags/%E8%A7%82%E5%90%8E%E6%84%9F/"/>
    
  </entry>
  
  <entry>
    <title>About Me</title>
    <link href="https://kzhoulatte.github.io/2017/04/09/About-Me/"/>
    <id>https://kzhoulatte.github.io/2017/04/09/About-Me/</id>
    <published>2017-04-09T21:38:07.000Z</published>
    <updated>2017-12-03T06:10:36.000Z</updated>
    
    <content type="html"><![CDATA[<p>&ensp;&ensp;I am a PhD candidate at UC Riverside. I am now focused on semiconductor research and data science. This is a personal blog which I use to help organize my thoughts.</p>
<p>&ensp;&ensp;My contacts are:<br>&ensp; &ensp; &ensp; &ensp; &ensp;     Cell: +1 (951)-318-1339<br>&ensp; &ensp; &ensp; &ensp; &ensp;     Email: kzhou003@ucr.edu</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&amp;ensp;&amp;ensp;I am a PhD candidate at UC Riverside. I am now focused on semiconductor research and data science. This is a personal blog wh
    
    </summary>
    
    
      <category term="Personal" scheme="https://kzhoulatte.github.io/tags/Personal/"/>
    
  </entry>
  
</feed>
